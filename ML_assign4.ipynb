{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "> **NOTE:** Instead of using Google Colab, I have switched to using Jupyter Notebook on my local machine for Q2 as imdb.com does not allow web scraping from headless mode, and Google Colab does not have a GUI rendering engine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeYGCm1zwR_u"
      },
      "source": [
        "# Lab Assignment 4\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KckH3Mxg2q4_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHz6T9kd33Ea"
      },
      "source": [
        "## Q1. Write a Python program to scrape all available books from the website [Books to Scrape](https://books.toscrape.com/) - a live site built for practicing scraping (safe, legal, no anti-bot).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqtSggz55oHv"
      },
      "source": [
        "For each book, extract the following details:\n",
        "1.   Title\n",
        "2.   Price\n",
        "3.   Availability (In stock / Out of stock)\n",
        "4.   Star Rating (One, Two, Three, Four, Five)\n",
        "\n",
        "Store the scraped results into a Pandas DataFrame and export them to a CSV file named books.csv.\n",
        "\n",
        "(Note: Use the requests library to fetch the HTML page. Use BeautifulSoup to parse and extract book details and handle pagination so that books from all pages are scraped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install beautifulsoup4 requests > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sSruzrYl7gTo"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QrI9CvqQ2rgX"
      },
      "outputs": [],
      "source": [
        "BASE_URL = \"https://books.toscrape.com/catalogue/category/books_1/page-{}.html\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VNiaf3g12u2f",
        "outputId": "121c5a9d-1611-4484-cf60-5c71aca0313e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraped 1000 books.\n"
          ]
        }
      ],
      "source": [
        "books = []\n",
        "page = 1\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        response = requests.get(BASE_URL.format(page))\n",
        "        html = response.text # response.content can be used to get HTML as a binary instead of an Unicode string\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {e}\")\n",
        "        break\n",
        "\n",
        "    book_tags = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "    if not book_tags or not response.ok:\n",
        "        break\n",
        "\n",
        "    for book_tag in book_tags:\n",
        "        book = {\n",
        "            'title': book_tag.h3.a[\"title\"], #type: ignore\n",
        "            'price': float(book_tag.find(\"p\", class_=\"price_color\").text[2:]), #type: ignore\n",
        "            'availability': book_tag.find(\"p\", class_=\"instock availability\").text.strip(), #type: ignore\n",
        "            'star_rating': book_tag.find(\"p\", class_=\"star-rating\")[\"class\"][1] #type: ignore\n",
        "        }\n",
        "        books.append(book)\n",
        "\n",
        "    page = page + 1\n",
        "\n",
        "print(f\"Scraped {len(books)} books.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "title",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "price",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "availability",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "star_rating",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "4a2bfb83-af2d-4194-945a-d22ab40de3a6",
              "rows": [
                [
                  "0",
                  "A Light in the Attic",
                  "51.77",
                  "In stock",
                  "Three"
                ],
                [
                  "1",
                  "Tipping the Velvet",
                  "53.74",
                  "In stock",
                  "One"
                ],
                [
                  "2",
                  "Soumission",
                  "50.1",
                  "In stock",
                  "One"
                ],
                [
                  "3",
                  "Sharp Objects",
                  "47.82",
                  "In stock",
                  "Four"
                ],
                [
                  "4",
                  "Sapiens: A Brief History of Humankind",
                  "54.23",
                  "In stock",
                  "Five"
                ]
              ],
              "shape": {
                "columns": 4,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>price</th>\n",
              "      <th>availability</th>\n",
              "      <th>star_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A Light in the Attic</td>\n",
              "      <td>51.77</td>\n",
              "      <td>In stock</td>\n",
              "      <td>Three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tipping the Velvet</td>\n",
              "      <td>53.74</td>\n",
              "      <td>In stock</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soumission</td>\n",
              "      <td>50.10</td>\n",
              "      <td>In stock</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sharp Objects</td>\n",
              "      <td>47.82</td>\n",
              "      <td>In stock</td>\n",
              "      <td>Four</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sapiens: A Brief History of Humankind</td>\n",
              "      <td>54.23</td>\n",
              "      <td>In stock</td>\n",
              "      <td>Five</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   title  price availability star_rating\n",
              "0                   A Light in the Attic  51.77     In stock       Three\n",
              "1                     Tipping the Velvet  53.74     In stock         One\n",
              "2                             Soumission  50.10     In stock         One\n",
              "3                          Sharp Objects  47.82     In stock        Four\n",
              "4  Sapiens: A Brief History of Humankind  54.23     In stock        Five"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(books)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Sgu5cdeN6Pe1"
      },
      "outputs": [],
      "source": [
        "df.to_csv('books.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agnfre7A5paQ"
      },
      "source": [
        "## Q2. Write a Python program to scrape the [IMDB Top 250 Movies list](https://www.imdb.com/chart/top/).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBLPAttF55G5"
      },
      "source": [
        "For each movie, extract the following details:\n",
        "\n",
        "1.   Rank (1-250)\n",
        "2.   Movie Title\n",
        "3.   Year of Release\n",
        "4.   IMDB Rating\n",
        "\n",
        "Store the results in a Pandas DataFrame and export it to a CSV file named imdb_top250.csv\n",
        "\n",
        "(Note: Use Selenium/Playwright to scrape the required details from this website)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install selenium webdriver-manager > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure that you have chromium installed using below command in system:-\n",
        "\n",
        "`sudo apt-get install -y chromium-browser`\n",
        "\n",
        "Use `which chromium-browser` to get path\n",
        "Use `chromium-browser --version` to get version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHROMIUM_PATH = \"/usr/bin/chromium-browser\"\n",
        "CHROMIUM_VERSION = \"140.0.7339.127\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "URL = \"https://www.imdb.com/chart/top/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setting up Chrome\n",
        "service = Service(ChromeDriverManager(CHROMIUM_VERSION).install())\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--remote-debugging-port=9222\") \n",
        "options.binary_location = CHROMIUM_PATH\n",
        "\n",
        "driver = webdriver.Chrome(\n",
        "    service=service,\n",
        "    options=options,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "driver.get(URL)\n",
        "\n",
        "# Wait until the list is visible\n",
        "wait = WebDriverWait(driver, 10)\n",
        "try:\n",
        "    movie_tags = wait.until(\n",
        "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.ipc-metadata-list-summary-item\"))\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Page load timeout: {e}\")\n",
        "    driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraped 250/250 movies.\n"
          ]
        }
      ],
      "source": [
        "movies = []\n",
        "for rank, movie_tag in enumerate(movie_tags, 1):\n",
        "\ttry:\n",
        "\t\tmovie = {\n",
        "\t\t\t\"rank\": rank,\n",
        "\t\t\t\"title\": movie_tag.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text.ipc-title__text--reduced\").text.split('. ')[1].strip(),\n",
        "\t\t\t\"release_year\": int(movie_tag.find_element(By.CSS_SELECTOR, \"span.sc-15ac7568-7.cCsint.cli-title-metadata-item\").text),\n",
        "\t\t\t\"rating\": float(movie_tag.find_element(By.CSS_SELECTOR, \"span.ipc-rating-star--rating\").text.strip())\n",
        "\t\t}\n",
        "\t\tmovies.append(movie)\n",
        "\texcept Exception as e:\n",
        "\t\tprint(f\"Error parsing movie at rank {rank}: {e}\")\n",
        "\n",
        "print(f\"Scraped {len(movies)}/250 movies.\")\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "rank",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "title",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "release_year",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "rating",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "39c89497-a3a8-48f7-ab91-0a24219b93c1",
              "rows": [
                [
                  "1",
                  "The Shawshank Redemption",
                  "1994",
                  "9.3"
                ],
                [
                  "2",
                  "The Godfather",
                  "1972",
                  "9.2"
                ],
                [
                  "3",
                  "The Dark Knight",
                  "2008",
                  "9.1"
                ],
                [
                  "4",
                  "The Godfather Part II",
                  "1974",
                  "9.0"
                ],
                [
                  "5",
                  "12 Angry Men",
                  "1957",
                  "9.0"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>release_year</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rank</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Shawshank Redemption</td>\n",
              "      <td>1994</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Godfather</td>\n",
              "      <td>1972</td>\n",
              "      <td>9.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Dark Knight</td>\n",
              "      <td>2008</td>\n",
              "      <td>9.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Godfather Part II</td>\n",
              "      <td>1974</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12 Angry Men</td>\n",
              "      <td>1957</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         title  release_year  rating\n",
              "rank                                                \n",
              "1     The Shawshank Redemption          1994     9.3\n",
              "2                The Godfather          1972     9.2\n",
              "3              The Dark Knight          2008     9.1\n",
              "4        The Godfather Part II          1974     9.0\n",
              "5                 12 Angry Men          1957     9.0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(movies).set_index('rank')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"imdb_top250.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxub7u7z6EN4"
      },
      "source": [
        "## Q3. Write a Python program to scrape the weather information for top world cities from the given website [timeanddate.com](https://www.timeanddate.com/weather/).\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNfdn-cP6P0e"
      },
      "source": [
        "For each city, extract the following details:\n",
        "\n",
        "1.   City Name\n",
        "2.   Temperature\n",
        "3.   Weather Condition (e.g., Clear, Cloudy, Rainy, etc.)\n",
        "\n",
        "Store the results in a Pandas DataFrame and export it to a CSV file named weather.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "URL = \"https://www.timeanddate.com/weather/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "\tresponse = requests.get(URL)\n",
        "\thtml = response.text\n",
        "\n",
        "\tsoup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "except Exception as e:\n",
        "\tprint(f\"ERROR: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bfjoFYhf5gby"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraped 140 cities.\n"
          ]
        }
      ],
      "source": [
        "weather = []\n",
        "\n",
        "weather_table = soup.find(\"table\", class_=\"zebra fw tb-theme\")\n",
        "weather_rows = weather_table.find_all(\"tr\")[1:] \t\t\t\t\t\t#type: ignore\n",
        "# Excludes the header row\n",
        "\n",
        "for row in weather_rows:\n",
        "    row_data = row.find_all(\"td\")\t\t\t\t\t\t\t\t\t\t#type: ignore\n",
        "    city_cells = [row_data[i:i + 4] for i in range(0, len(row_data), 4)]\n",
        "    for city in city_cells:\n",
        "        try:\n",
        "            city_weather = {\n",
        "                \"id\": int(city[1][\"id\"].strip(\"p\")),\t\t\t\t\t#type: ignore\t\n",
        "                \"city\": city[0].a.text.strip(),\t\t\t\t\t\t\t#type: ignore\n",
        "\t\t\t\t\"temperature_celsius\": int(city[3].text.strip()[:-3]),\n",
        "                \"weather_condn\": city[2].img[\"title\"].strip(), \t\t\t#type: ignore\n",
        "\t\t\t}\n",
        "            weather.append(city_weather)\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing city weather: {e}\")\n",
        "\n",
        "print(f\"Scraped {len(weather)} cities.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "id",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "city",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "temperature_celsius",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "weather_condn",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "1f2ebc5b-0b59-4303-b15d-816c2693ff4f",
              "rows": [
                [
                  "0",
                  "Accra",
                  "26",
                  "Scattered clouds. Warm."
                ],
                [
                  "1",
                  "Addis Ababa",
                  "18",
                  "Passing clouds. Mild."
                ],
                [
                  "2",
                  "Adelaide",
                  "10",
                  "Quite cool."
                ],
                [
                  "3",
                  "Algiers",
                  "26",
                  "Passing clouds. Warm."
                ],
                [
                  "4",
                  "Almaty",
                  "18",
                  "Mostly cloudy. Mild."
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>temperature_celsius</th>\n",
              "      <th>weather_condn</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accra</td>\n",
              "      <td>26</td>\n",
              "      <td>Scattered clouds. Warm.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Addis Ababa</td>\n",
              "      <td>18</td>\n",
              "      <td>Passing clouds. Mild.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelaide</td>\n",
              "      <td>10</td>\n",
              "      <td>Quite cool.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Algiers</td>\n",
              "      <td>26</td>\n",
              "      <td>Passing clouds. Warm.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Almaty</td>\n",
              "      <td>18</td>\n",
              "      <td>Mostly cloudy. Mild.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           city  temperature_celsius            weather_condn\n",
              "id                                                           \n",
              "0         Accra                   26  Scattered clouds. Warm.\n",
              "1   Addis Ababa                   18    Passing clouds. Mild.\n",
              "2      Adelaide                   10              Quite cool.\n",
              "3       Algiers                   26    Passing clouds. Warm.\n",
              "4        Almaty                   18     Mostly cloudy. Mild."
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(weather).set_index(\"id\").sort_index()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"weather.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPHKHjiiQnemoD/hoQEen2m",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml-assign",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
